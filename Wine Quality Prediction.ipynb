{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdff62a3-a7c3-42d2-a157-34c00208d61f",
   "metadata": {},
   "source": [
    "## Wine Quality Prediction \n",
    "**Binary Classification: Good Wine vs Bad Wine**\n",
    "\n",
    "### Objective:\n",
    "The goal of this project is to build a complete Machine Learning pipeline using a real-world dataset. The task is to predict whether a wine sample is Good (quality ≥ 7) or Bad (quality < 7) based on its chemical properties.\n",
    "\n",
    "**This notebook covers the full ML workflow including:**\n",
    "\n",
    "Dataset understanding\n",
    "\n",
    "Data inspection and cleaning\n",
    "\n",
    "Exploratory Data Analysis (EDA)\n",
    "\n",
    "Feature engineering\n",
    "\n",
    "Model training & evaluation\n",
    "\n",
    "Model comparison\n",
    "\n",
    "Hyperparameter tuning using Pipeline + GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61483803-4725-480d-90a8-cfd274ad6f96",
   "metadata": {},
   "source": [
    "### TASK 1: Load and Understand the Dataset\n",
    "**Introduction**\n",
    "\n",
    "In this task, the dataset winequality.csv was loaded using Pandas to understand its structure. This dataset contains wine samples with different chemical properties, and our goal is to predict wine quality using these features.\n",
    "\n",
    "**Result / Findings**\n",
    "\n",
    "The dataset contains numerical chemical measurement features such as acidity, sugar, sulphates, pH, and alcohol.\n",
    "\n",
    "Each row represents one wine sample.\n",
    "\n",
    "Each column represents a chemical property, and the column quality represents the wine quality score given to that sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14aa3acd-d09b-4644-9bbb-6b9ea28e0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fe7b3b-aa48-4e44-9132-77b19f9808e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54febce5-26da-4e34-920d-fb858c306c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b22284-0e8c-47d7-b161-2e4dc934b275",
   "metadata": {},
   "source": [
    "### TASK 2: Basic Data Inspection\n",
    "**Introduction**\n",
    "\n",
    "Before applying Machine Learning algorithms, it is important to inspect the dataset. This helps identify the dataset size, column names, data types, and the overall statistical distribution of data.\n",
    "\n",
    "**Result / Findings**\n",
    "\n",
    "The dataset has 1599 rows and 12 columns.\n",
    "\n",
    "All columns are numerical.\n",
    "\n",
    "The target variable is quality, which contains wine quality scores.\n",
    "\n",
    "**Why Data Inspection is Important**\n",
    "\n",
    "Data inspection is important because it helps us:\n",
    "\n",
    "understand the structure of the dataset,\n",
    "\n",
    "identify datatype issues,\n",
    "\n",
    "detect unusual values,\n",
    "\n",
    "and plan preprocessing steps before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85fb1c6-4a12-4196-90e4-5342e641dc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60743fb-f464-431d-9954-54ae40775554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba7a6c-a986-4c17-bcaa-82978573194c",
   "metadata": {},
   "source": [
    "### TASK 3: Missing Values Analysis\n",
    "**Introduction**\n",
    "\n",
    "Missing values can reduce model accuracy or create bias in predictions. In real-world projects, handling missing data properly is critical.\n",
    "\n",
    "**Result / Findings**\n",
    "\n",
    "After checking the dataset using isnull() and isnull().sum(), it was found that:\n",
    "There are no missing values in the dataset (0 null values).\n",
    "\n",
    "**Real-world Handling (If missing values existed)**\n",
    "\n",
    "If missing values were present, we could handle them by:\n",
    "\n",
    "removing missing rows (if very few),\n",
    "\n",
    "imputing values using mean/median (for numerical features),\n",
    "\n",
    "or using model-based imputation in advanced cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b31479-55a8-425f-8171-f445d60904d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0             False             False        False           False      False   \n",
       "1             False             False        False           False      False   \n",
       "2             False             False        False           False      False   \n",
       "3             False             False        False           False      False   \n",
       "4             False             False        False           False      False   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594          False             False        False           False      False   \n",
       "1595          False             False        False           False      False   \n",
       "1596          False             False        False           False      False   \n",
       "1597          False             False        False           False      False   \n",
       "1598          False             False        False           False      False   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
       "0                   False                 False    False  False      False   \n",
       "1                   False                 False    False  False      False   \n",
       "2                   False                 False    False  False      False   \n",
       "3                   False                 False    False  False      False   \n",
       "4                   False                 False    False  False      False   \n",
       "...                   ...                   ...      ...    ...        ...   \n",
       "1594                False                 False    False  False      False   \n",
       "1595                False                 False    False  False      False   \n",
       "1596                False                 False    False  False      False   \n",
       "1597                False                 False    False  False      False   \n",
       "1598                False                 False    False  False      False   \n",
       "\n",
       "      alcohol  quality  \n",
       "0       False    False  \n",
       "1       False    False  \n",
       "2       False    False  \n",
       "3       False    False  \n",
       "4       False    False  \n",
       "...       ...      ...  \n",
       "1594    False    False  \n",
       "1595    False    False  \n",
       "1596    False    False  \n",
       "1597    False    False  \n",
       "1598    False    False  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc78e16-0e55-499c-b999-d09bfcbdb2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd0a72-9cd9-419d-8f1c-93e451309516",
   "metadata": {},
   "source": [
    "### TASK 4: Exploratory Data Analysis (EDA)\n",
    "**Introduction**\n",
    "\n",
    "EDA helps understand the distribution of the target variable and identify patterns in the dataset. Here, we focused on analyzing the quality column.\n",
    "\n",
    "**Result / Findings** \n",
    "\n",
    "The value counts of wine quality are:\n",
    "\n",
    "Quality 3: 10\n",
    "\n",
    "Quality 4: 53\n",
    "\n",
    "Quality 5: 681\n",
    "\n",
    "Quality 6: 638\n",
    "\n",
    "Quality 7: 199\n",
    "\n",
    "Quality 8: 18\n",
    "\n",
    "**Observations**\n",
    "\n",
    "The dataset is heavily concentrated around quality scores 5 and 6, meaning most wines are average quality.\n",
    "\n",
    "Very few wines have extreme ratings like 3 or 8, showing fewer samples of poor and excellent wines.\n",
    "\n",
    "The dataset is not uniformly distributed, which can affect model performance.\n",
    "\n",
    "**Why EDA is Helpful**\n",
    "\n",
    "EDA helps before training because it:\n",
    "\n",
    "reveals imbalance and skewness,\n",
    "\n",
    "shows whether enough samples exist for each class,\n",
    "\n",
    "and helps choose the right ML approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bcc2401-f2f9-4112-9b9b-e460004d3558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "3     10\n",
       "4     53\n",
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "8     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"quality\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d1bf31a-7681-41de-a721-25e443fe9cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganji Niharika\\AppData\\Local\\Temp\\ipykernel_12696\\1788410844.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x=\"quality\", data=df, palette=custom_colors)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "custom_colors = [\"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B3\", \"#CCB974\", \"#64B5CD\"]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x=\"quality\", data=df, palette=custom_colors)\n",
    "plt.title(\"Distribution of Wine Quality Scores\")\n",
    "plt.xlabel(\"Quality Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f31c2-5fcf-458c-b1c2-a68613c9fb17",
   "metadata": {},
   "source": [
    "### TASK 5: Convert the Problem into a Classification Task\n",
    "**Introduction**\n",
    "\n",
    "Predicting exact wine quality is a binary classification problem and can be difficult. In practical systems, businesses often only care whether a wine is “good” or “bad”, so we convert it into a binary target label based on the quality scores.\n",
    "\n",
    "**Result / Findings**\n",
    "\n",
    "A new column quality_label was created using this rule:\n",
    "\n",
    "quality ≥ 7 → Good Wine (1)\n",
    "\n",
    "quality < 7 → Bad Wine (0)\n",
    "\n",
    "**After conversion:**\n",
    "\n",
    "Bad Wine (0): 1382 samples\n",
    "\n",
    "Good Wine (1): 217 samples\n",
    "\n",
    "**Why Binary Classification is More Useful**\n",
    "\n",
    "Binary classification is useful because:\n",
    "\n",
    "it’s easier to deploy and interpret,\n",
    "\n",
    "decision-making becomes clearer,\n",
    "\n",
    "and it matches real-world needs like recommending good wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12b2f378-f696-4561-b589-6cf8999d75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " df[\"quality_label\"] = (df[\"quality\"] >= 7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ede27fc-5e95-49ed-a113-904b50cefe97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality  quality_label\n",
       "0        5              0\n",
       "1        5              0\n",
       "2        5              0\n",
       "3        6              0\n",
       "4        5              0\n",
       "5        5              0\n",
       "6        5              0\n",
       "7        7              1\n",
       "8        7              1\n",
       "9        5              0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"quality\", \"quality_label\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0360e418-abad-48f3-add7-5d8667846075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality_label\n",
       "0    1382\n",
       "1     217\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"quality_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe53095-1d09-45b6-b3a3-c0c1e52997af",
   "metadata": {},
   "source": [
    "### TASK 6: Feature and Target Separation\n",
    "**Introduction**\n",
    "\n",
    "Machine Learning requires separating input variables (features) and output variable (target). Here we define features X and label y.\n",
    "\n",
    "**Result / Findings**\n",
    "\n",
    "X (features): All chemical properties\n",
    "\n",
    "y (target): quality_label\n",
    "\n",
    "**Why Not Use quality as Input Feature**\n",
    "\n",
    "The original quality column is the true output/label. Using it as a feature would cause data leakage, meaning the model would cheat by learning directly from the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "675308c5-defc-4d2c-ae7d-fa4164b39855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       " 0            7.4              0.70         0.00             1.9      0.076   \n",
       " 1            7.8              0.88         0.00             2.6      0.098   \n",
       " 2            7.8              0.76         0.04             2.3      0.092   \n",
       " 3           11.2              0.28         0.56             1.9      0.075   \n",
       " 4            7.4              0.70         0.00             1.9      0.076   \n",
       " \n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       " 0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       " 1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       " 2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       " 3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       " 4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       " \n",
       "    alcohol  \n",
       " 0      9.4  \n",
       " 1      9.8  \n",
       " 2      9.8  \n",
       " 3      9.8  \n",
       " 4      9.4  ,\n",
       " 0    0\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " Name: quality_label, dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"quality\", \"quality_label\"])\n",
    "y = df[\"quality_label\"]\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b86e92-ff8e-4887-9f9f-61385b1b8ea5",
   "metadata": {},
   "source": [
    "### TASK 7: Train–Test Split\n",
    "**Introduction**\n",
    "\n",
    "To test how well the model performs on unseen data, we split the dataset into training and testing sets.\n",
    "\n",
    "**Result / Findings**\n",
    "\n",
    "The dataset was split into:\n",
    "\n",
    "Training set: 80%\n",
    "\n",
    "Testing set: 20%\n",
    "\n",
    "random_state = 42 was used for reproducibility.\n",
    "\n",
    "**Why do we split data into training and testing sets?**\n",
    "\n",
    "We split the dataset into training and testing sets so we can:\n",
    "\n",
    "Train the model on the training data (learn patterns and relationships)\n",
    "\n",
    "Evaluate the model on the testing data (check performance on unseen data)\n",
    "\n",
    "This gives a realistic estimate of how the model will perform in the real world, where it will always receive new/unseen inputs.\n",
    "\n",
    "**What problem occurs if we train and test on the same data?**\n",
    "\n",
    "If we train and test on the same data, the model may:\n",
    "\n",
    "Memorize the data instead of learning general patterns\n",
    "\n",
    "Show artificially high accuracy\n",
    "\n",
    "Fail badly on new data\n",
    "\n",
    "#### This problem is called:\n",
    "\n",
    "**Overfitting (and also \"data leakage\" in evaluation sense)**\n",
    "\n",
    "Stratification ensures that both training and testing sets maintain the same class distribution, which is important for imbalanced datasets. This prevents overfitting and provides a realistic evaluation of model performance.\n",
    "\n",
    "So basically:\n",
    "Testing on training data = fake performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881a3aab-2d61-4cb4-b252-25fe74ee424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,       # 80% train, 20% test\n",
    "    random_state=42,     # reproducibility\n",
    "    stratify=y           # critical due to imbalance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2654b6e-82ec-460d-9360-0a95cd9a7515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(quality_label\n",
       " 0    1109\n",
       " 1     170\n",
       " Name: count, dtype: int64,\n",
       " quality_label\n",
       " 0    273\n",
       " 1     47\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca6d9d-83c4-4545-9f10-239331a00a54",
   "metadata": {},
   "source": [
    "### TASK 8: Feature Scaling (StandardScaler) \n",
    "**Introduction**\n",
    "\n",
    "**Why is Feature Scaling Important?**\n",
    "\n",
    "Feature scaling is important because different features in the wine dataset have different value ranges.\n",
    "Example:\n",
    "\n",
    "pH values are around 3\n",
    "\n",
    "total sulfur dioxide can go above 100\n",
    "\n",
    "alcohol may range around 8–14\n",
    "\n",
    "If we do not scale the features, the ML model may give more importance to large-range features, not because they are more important, but simply because their values are numerically bigger.\n",
    "\n",
    "Scaling ensures that all features contribute equally and prevents models from being biased toward features with larger numeric ranges.\n",
    "\n",
    "Scaling helps by: making all features comparable on the same scale, improving model stability, increasing training speed for some algorithms, improving accuracy for distance/optimization based models.\n",
    "\n",
    "Note: Logistic Regression, KNN, and SVM require scaling, while tree-based models do not.\n",
    "\n",
    "**Why Fit on Training Data Only?**\n",
    "\n",
    "We fit StandardScaler only on training data because the scaler learns:\n",
    "\n",
    "mean (average)\n",
    "\n",
    "standard deviation\n",
    "\n",
    "If we fit it on the full dataset (train + test), we are indirectly using information from the test set.\n",
    "\n",
    "That causes data leakage, meaning the test data is no longer truly unseen.\n",
    "\n",
    "**Correct approach:**\n",
    "\n",
    "Fit scaler on train\n",
    "\n",
    "Transform train\n",
    "\n",
    "Transform test using same scaler\n",
    "\n",
    "**Which ML Models Need Scaling and Why?**\n",
    "\n",
    "Scaling is mainly needed for models that rely on:\n",
    "\n",
    "**1) Distance-Based Algorithms**\n",
    "\n",
    "These models use distance calculations (Euclidean, etc).\n",
    "If features are not scaled, the feature with the largest range dominates the distance.\n",
    "\n",
    "Examples:\n",
    "\n",
    "KNN (K-Nearest Neighbors)\n",
    "\n",
    "SVM (Support Vector Machine) (especially with RBF kernel)\n",
    "\n",
    "**Why scaling matters:**\n",
    "Because distance is affected heavily by feature magnitude.\n",
    "\n",
    "**2) Gradient-Based Algorithms**\n",
    "\n",
    "These models use gradient descent / optimization to find best parameters.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "SVM (Linear)\n",
    "\n",
    "**Why scaling matters:**\n",
    "\n",
    "Makes optimization faster\n",
    "\n",
    "Makes coefficients stable\n",
    "\n",
    "Helps converge properly\n",
    "\n",
    "**Models That Do NOT Need Scaling**\n",
    "\n",
    "Tree-based models do not depend on distance or gradients in the same way.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Decision Tree\n",
    "\n",
    "Random Forest\n",
    "\n",
    "**Reason:**\n",
    "Trees split based on conditions like:\n",
    "\n",
    "alcohol > 10.5\n",
    "Scaling does not change the order of values, so tree decisions remain mostly unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c05bba8e-182c-4bc3-89a6-fa003d838a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38adc8bc-7f92-4c97-a088-ac0dacbf7a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21833164,  0.88971201,  0.19209222,  0.30972563, -0.04964208,\n",
       "         0.69100692,  1.04293362,  1.84669643,  1.09349989,  0.45822284,\n",
       "         1.12317723],\n",
       "       [-1.29016623, -1.78878251,  0.65275338, -0.80507963, -0.45521361,\n",
       "         2.38847304,  3.59387025, -3.00449133, -0.40043872, -0.40119696,\n",
       "         1.40827174],\n",
       "       [ 1.49475291, -0.78434707,  1.01104539, -0.52637831,  0.59927236,\n",
       "        -0.95796016, -0.99174203,  0.76865471, -0.07566946,  0.51551749,\n",
       "        -0.58738978],\n",
       "       [ 0.27635078,  0.86181102, -0.06383064, -0.66572897, -0.00908493,\n",
       "         0.01202048, -0.71842739,  0.08948842,  0.05423824, -1.08873281,\n",
       "        -0.96751578],\n",
       "       [ 0.04427419,  2.81487994, -0.62686095,  2.39998549, -0.31326357,\n",
       "        -0.47296984,  0.2229897 ,  1.1998714 ,  0.37900751, -0.9741435 ,\n",
       "        -0.49235828]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af18a4-cf0d-4264-97ff-f02fa9e5f253",
   "metadata": {},
   "source": [
    "### TASK 9: Model Training \n",
    "**Introduction**\n",
    "\n",
    "In this task, multiple Machine Learning classification models are trained to predict whether a wine is Good (1) or Bad (0). Different algorithms learn patterns differently, so training several models allows us to compare performance and select the most suitable model for this dataset.\n",
    "\n",
    "**Models Trained (with basic working explanation)**\n",
    "\n",
    "**1) Logistic Regression (Scaled Data)**\n",
    "\n",
    "Logistic Regression is a linear classification algorithm that predicts the probability of a sample belonging to a class using the sigmoid function. It finds a linear decision boundary that best separates Good and Bad wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f563b0fc-a01c-4d52-9783-2c3dac371b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_preds = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d290b50-aa03-4809-ad2e-354507883c18",
   "metadata": {},
   "source": [
    "**2) K-Nearest Neighbors – KNN (Scaled Data)**\n",
    "\n",
    "KNN is a distance-based model that classifies a wine by looking at the K closest samples in the training data. The final class is chosen based on the majority class among those neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0013b6f1-a454-46d2-86fd-4ef7cb11828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn_preds = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb390d8-b076-4db3-9319-09ed19411359",
   "metadata": {},
   "source": [
    "**3) Support Vector Machine – SVM (Scaled Data)**\n",
    "\n",
    "SVM works by finding the optimal separating boundary (hyperplane) between classes with the maximum margin. With kernels (like RBF), it can model complex non-linear boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04457d68-7eb3-4328-94a2-0cd1d28326df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_preds = svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d7160c-2455-4b9a-9b5b-8aa66dc0ce19",
   "metadata": {},
   "source": [
    "**4) Decision Tree Classifier (Unscaled Data)**\n",
    "\n",
    "A Decision Tree works by splitting the dataset into branches using if–else style rules on feature values. It creates a tree structure where each split is chosen to maximize class separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "814d5c63-7ea6-4df8-adf0-89b118252797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_preds = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200d99f-e86b-42ec-931f-3d373c182f42",
   "metadata": {},
   "source": [
    "**5) Random Forest Classifier (Unscaled Data)**\n",
    "\n",
    "Random Forest is an ensemble method that builds many decision trees and combines their predictions. It reduces overfitting compared to a single tree and generally provides better accuracy and stability.\n",
    "\n",
    "**Note on Scaling**\n",
    "\n",
    "**Scaled models:** Logistic Regression, KNN, SVM\n",
    "**Unscaled models:** Decision Tree, Random Forest\n",
    "\n",
    "Scaling is essential for distance-based and gradient-based models to ensure fair feature contribution and better convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3608a24b-41d6-44a7-a771-357c26013f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c92440-0c0b-4536-9b57-55abc1a6dd42",
   "metadata": {},
   "source": [
    "### TASK 10: Model Evaluation and Comparison \n",
    "**Introduction**\n",
    "\n",
    "After training different machine learning models, we need to check which model gives the best results. So, we calculate the accuracy of each model and compare them.\n",
    "\n",
    "**Accuracy Results**\n",
    "\n",
    "Model\tAccuracy:\n",
    "Logistic Regression\t0.8656, \n",
    "KNN\t0.8813, \n",
    "Decision Tree\t0.8719, \n",
    "Random Forest\t0.9000, \n",
    "SVM\t0.8750\n",
    "\n",
    "**Which model performed the best?**\n",
    "\n",
    "Random Forest performed the best because it got the highest accuracy: 0.90 (90%)\n",
    "\n",
    "**Why Random Forest performed better?**\n",
    "\n",
    "Random Forest performed better because:\n",
    "\n",
    "It uses many decision trees and combines their results.\n",
    "\n",
    "It gives more accurate and stable predictions than one single decision tree.\n",
    "\n",
    "It handles complex patterns in the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "409d20a5-a3bf-47fe-89a4-3554412e7629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.865625,\n",
       " 'KNN': 0.88125,\n",
       " 'Decision Tree': 0.871875,\n",
       " 'Random Forest': 0.9,\n",
       " 'SVM': 0.875}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = {\n",
    "    \"Logistic Regression\": accuracy_score(y_test, lr_preds),\n",
    "    \"KNN\": accuracy_score(y_test, knn_preds),\n",
    "    \"Decision Tree\": accuracy_score(y_test, dt_preds),\n",
    "    \"Random Forest\": accuracy_score(y_test, rf_preds),\n",
    "    \"SVM\": accuracy_score(y_test, svm_preds),\n",
    "}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20be08cc-4043-40b2-914e-ec476afd4213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.871875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.865625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "3        Random Forest  0.900000\n",
       "1                  KNN  0.881250\n",
       "4                  SVM  0.875000\n",
       "2        Decision Tree  0.871875\n",
       "0  Logistic Regression  0.865625"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = {\n",
    "    \"Logistic Regression\": accuracy_score(y_test, lr_preds),\n",
    "    \"KNN\": accuracy_score(y_test, knn_preds),\n",
    "    \"Decision Tree\": accuracy_score(y_test, dt_preds),\n",
    "    \"Random Forest\": accuracy_score(y_test, rf_preds),\n",
    "    \"SVM\": accuracy_score(y_test, svm_preds),\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(\n",
    "    results.items(), columns=[\"Model\", \"Accuracy\"]\n",
    ").sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85a70cf9-c81a-449a-8d40-49ec456a5f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      " [[264   9]\n",
      " [ 23  24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       273\n",
      "           1       0.73      0.51      0.60        47\n",
      "\n",
      "    accuracy                           0.90       320\n",
      "   macro avg       0.82      0.74      0.77       320\n",
      "weighted avg       0.89      0.90      0.89       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033a819-39c1-482f-9f0a-b853e9c32c09",
   "metadata": {},
   "source": [
    "### TASK 11: Pipeline and Hyperparameter Tuning \n",
    "**Introduction**\n",
    "\n",
    "In this task, we use a Pipeline and GridSearchCV to improve the model performance. A pipeline helps us combine preprocessing (scaling) and model training in one step. GridSearchCV helps us find the best hyperparameters for the model.\n",
    "\n",
    "**What is a Pipeline and Why Do We Use It?**\n",
    "\n",
    "A pipeline is used to connect multiple steps like:\n",
    "\n",
    "StandardScaler (Scaling)\n",
    "\n",
    "Model training (Logistic Regression / SVM)\n",
    "\n",
    "**Why pipelines are used in real-world ML systems:**\n",
    "\n",
    "It makes the workflow clean and organized\n",
    "\n",
    "Prevents mistakes and data leakage\n",
    "\n",
    "Makes the model easier to reuse and deploy\n",
    "\n",
    "Ensures scaling and training happen in the correct order every time\n",
    "\n",
    "**What is Hyperparameter Tuning?**\n",
    "\n",
    "Hyperparameters are settings that we choose before training a model.\n",
    "Example:\n",
    "\n",
    "C in Logistic Regression / SVM\n",
    "\n",
    "kernel in SVM\n",
    "\n",
    "These affect model performance.\n",
    "\n",
    "**Why do we use GridSearchCV?**\n",
    "\n",
    "GridSearchCV tests many combinations of parameters automatically and selects the best one using cross-validation.\n",
    "\n",
    "What it gives us:\n",
    "\n",
    "Best parameters\n",
    "\n",
    "Best cross-validation score\n",
    "\n",
    "**Why Hyperparameter Tuning Improves Performance**\n",
    "\n",
    "Hyperparameter tuning improves performance because:\n",
    "\n",
    "The default settings may not be best for our dataset\n",
    "\n",
    "It helps the model find the best configuration\n",
    "\n",
    "It can increase accuracy and reduce errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b02bbfe-5130-4984-ac85-89494e20c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "851157de-3581-43c1-bd11-74bec4fe6085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'svm__C': 100, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "Best CV F1: 0.5671102970074522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"svm__C\": [0.1, 1, 10, 100],\n",
    "    \"svm__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1\",   # better than accuracy because class 1 is minority\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef715509-ba1c-454e-bb69-20fee6eddd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM Test Accuracy: 0.909375\n",
      "Confusion Matrix:\n",
      " [[262  11]\n",
      " [ 18  29]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       273\n",
      "           1       0.72      0.62      0.67        47\n",
      "\n",
      "    accuracy                           0.91       320\n",
      "   macro avg       0.83      0.79      0.81       320\n",
      "weighted avg       0.90      0.91      0.91       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "print(\"Tuned SVM Test Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac47ca-0a86-4d44-b503-995c700bc87b",
   "metadata": {},
   "source": [
    "### TASK 12: Final Conclusion \n",
    "**Conclusion**\n",
    "\n",
    "In this project, we worked on the Wine Quality dataset, where each row represents one wine sample and each column represents a chemical property of wine. The target column quality was used to predict wine quality.\n",
    "\n",
    "From EDA, we observed that most wines have quality scores around 5 and 6, meaning the dataset contains more average-quality wines and fewer high-quality wines. We also converted the problem into a binary classification task:\n",
    "\n",
    "Good Wine (quality ≥ 7)\n",
    "\n",
    "Bad Wine (quality < 7)\n",
    "\n",
    "We trained and tested different machine learning models such as Logistic Regression, KNN, Decision Tree, Random Forest, and SVM. Among them, Random Forest performed the best with the highest accuracy of 0.90 (90%).\n",
    "\n",
    "Through this project, I learned how to build an end-to-end machine learning workflow, including data loading, inspection, EDA, feature scaling, model training, evaluation, and improving performance using pipeline and hyperparameter tuning.\n",
    "\n",
    "This project is similar to real-world ML applications because it follows the same steps used in industry: preparing data, selecting models, evaluating performance on test data, and tuning the model to achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe06354-40ff-4967-b744-cc76308a90ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
